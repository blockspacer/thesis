\chapter*{Abstract}                      % ne pas num√©roter
\phantomsection\addcontentsline{toc}{chapter}{Abstract} % inclure dans TdM

\begin{otherlanguage*}{english}

  Image analysis and modification tasks have a plethora of applications, from compositing to image relighting through the 3D object reconstruction. These tasks allow the realization of masterpieces or decision-making based on visual stimuli. However, it is necessary to reason globally on the scene in order to obtain plausible and appreciable results. For many of these tasks, the physical and geometric models that the scientific community has developed give rise to ill-posed problems with several solutions, only one of which is reasonable. To resolve these indeterminations, the reasoning about the visual and semantic context of a scene is usually relayed to an artist who uses his experience to carry out his work. Would it be possible to model the experiment from visual data and automate some or all of these tasks? This is the subject of this thesis: modeling priors by deep machine learning to allow the solving of typically ill-posed problems. More specifically, we will cover three research axes: 1) surface reconstruction using photometric cues, 2) outdoor illumination estimation from a single image and 3) camera calibration estimation from an image with generic content. These three topics will be addressed from a data-driven perspective. Each of these axes includes in-depth performance analyses and, despite the reputation of opacity of deep machine learning algorithms, we offer studies on the visual cues captured by our methods.

\end{otherlanguage*}
