%!TEX root = main.tex
\chapter*{Conclusion}         % ne pas num√©roter
\phantomsection\addcontentsline{toc}{chapter}{Conclusion} % dans TdM


Throughout this thesis, we leverage the fact that gathering and analyzing large datasets can bring new insights that can both improve classical methods and build advanced machine learning algorithms. Three main axes of research were presented. First, we proposed a framework to analyze the performance of outdoor Photometric Stereo, which can explain the reasons leading to accurate tridimensional surface reconstruction through photometric signal under daylight. Using this framework, we demonstrated that partially cloudy days are more suited to perform outdoor PS from the photometric signal alone. We also showed that clear days typically do not yield enough photometric information to perform a robust surface reconstruction. We then presented a learning-based method that augments photometric cues with priors to solve the instability of the PS problem during sunny days. Secondly, we proposed a single image learning-based algorithm for outdoor lighting estimation that is robust to various scene content and exhibits state-of-the-art performance. We achieved this by fitting the physics-based Ho\v{s}ek-Wilkie sky model to a large dataset of 360$\degr$ panoramas and used it to train our machine learning model. Lastly, we used a similar approach to create a camera calibration method, which estimates automatically the field of view and the position of the horizon within the image. These last two methods can be used to streamline compositing operations by enabling automatic photorealistic virtual object insertion and relighting, along with applications like image retrieval. All proposed methods work on generic scenes and rely heavily on the priors modeled directly from the training data. 

For every project presented, we strove to understand the underlying patterns in the data. We proposed a framework for photometric stereo sensitivity analysis, which can predict reconstruction performance from the sky appearance. We also experimented with our surface reconstruction approach under various configurations to better understand the impact of camera calibration error and the number of input images on the reconstruction performance. Furthermore, the proposed camera calibration estimation method was analyzed through guided backpropagation, which allowed us to better understand the visual cues picked up by the learned model. Even though deep learning models are generally considered \emph{black boxes} by the community, we hope our efforts in explaining the behavior of those machine learning methods have inspired others to continue in this direction.

All approaches described in this thesis have direct applications in entertainment and advertisement, notably by enabling photorealistic virtual object insertion and relighting automatically. The lighting estimation and camera calibration techniques presented in this thesis (see chapters~\ref{ch3} and~\ref{ch4}) received worldwide recognition and were implemented into Dimension, the new 3D editing software from Adobe Systems. Thanks to these new technologies, multimedia artists are reporting their increased productivity and reduced time needed to create or modify works, as shown in the following testimony from a user: ``One of the greatest features is Dimension's ability to derive lighting from an image [and] use that to light an object. Results are amazing.'' In addition to its influence on digital media artists, the techniques proposed in this thesis also had an impact on the scientific community. We were selected to make an oral presentation at CVPR for our proposed lighting estimation method, a prestigious distinction (3\% acceptance rate in a conference holding an h-index impact score of 158). We also won the \emph{Best Paper (Runner Up)} award in 2015 at 3DV for the work presented in chapter~\ref{ch1}, which analyzed and improved outdoor surface reconstruction through photometric stereo. When applied outdoor, this technique can also have a large-scale impact, as it can be used to perform 3D scans of large statues and buildings, where hand-held scanning would take a prohibitive amount of time. The video game and movie industries use similar techniques to digitize actors~\cite{debevec2000acquiring} to produce photorealistic alter-egos. Using our proposed approach, the same could be done for large-scale elements like buildings and would allow studios to easily obtain high fidelity models for their creations. Aside from the entertainment industry, this technique can allow the preservation of cultural heritage of statues and buildings through digital copies that will stand the test of time. Additionally, the light and camera parameters estimation techniques we developed can also provide additional information to sensors, improving the quality of information provided by decision support systems. Similarly, our approaches could complement robot navigation and localization systems by providing another source of attitude estimation based on visual cues. Image forensics can also benefit from the ideas proposed in this thesis: detecting shadow orientations (by estimating sun position) and detecting conflicting horizons can help discover image modifications~\cite{Farid2010}. As can be seen, modeled priors can be used to perform hard computer vision tasks and have a myriad of applications.

Notwithstanding the advances proposed in this thesis, there are still some limitations to the presented approaches. For instance, the proposed method for outdoor surface reconstruction during sunny days expects the camera to point toward the north. A fully uncalibrated outdoor photometric stereo method has not yet been discovered. Also, while our lighting estimation method can predict accurately the sun position and most of the energy of the sky, it cannot model accurately its texture, as it models clouds as fog. Lastly, our proposed approach for camera calibration estimation does not support extreme pitch and roll angles due to the camera orientation representation we employed. We believe these limitations can be lifted in the foreseeable future by extending the approaches proposed in this thesis. On a broader note, it is our hope that this thesis has brought some insights and tools to enable the next generation of deep learned priors to computer vision tasks. 
