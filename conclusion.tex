%!TEX root = main.tex
\chapter*{Conclusion}         % ne pas num√©roter
\phantomsection\addcontentsline{toc}{chapter}{Conclusion} % dans TdM


Throughout this thesis, we show that gathering and analyzing large datasets can bring new insights that can both improve classical methods and build advanced machine learning algorithms. Three main axes of research were presented: first, tridimensional surface reconstruction through photometric signal. Then, we proposed two single image learning-based algorithms, one for outdoor lighting estimation and a second one for camera calibration. All proposed methods work on generic scenes and rely heavily on the priors learned directly from the training data. 

For every project presented, we strove to understand the underlying patterns in the data. We proposed a framework for photometric stereo sensitivity analysis, which can predict reconstruction performance from the sky appearance. We also experimented with our surface reconstruction approach under various configurations to better understand the impact of camera calibration error and the number of input images on the reconstruction performance. Furthermore, the proposed camera calibration estimation method was analyzed through guided backpropagation, which allowed us to better understand the visual cues picked up by the learned model. Even though deep learning models are generally considered \emph{black boxes} by the community, we hope our efforts in explaining the behavior of those machine learning methods have inspired others to continue in this direction.

All projects could not have been possible without the hundreds of thousands of sky panoramas we captured or that was available in the SUN360 dataset~\cite{xiao-cvpr-12}. This large amount of data was crucial for both analyzing and training our methods. As machine learning techniques continue to improve, we can expect more complex structure and priors to be extracted by deep learning methods from less and less structured data in the near future. Computer vision methods has a lot to gain from such improvements, providing them extra constraints when physics or geometric constraints alone cannot solve a problem robustly. It is our hope that this thesis has brought some insights and tools to enable the next generation of deep learned priors to computer vision tasks. 
