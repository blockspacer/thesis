%!TEX root = main.tex
\chapter*{Introduction}         % ne pas numéroter
\phantomsection\addcontentsline{toc}{chapter}{Introduction} % inclure dans TdM

% General
Natural images are but a glimpse of captured light. They depict a morning in the park, some afternoon in the living room or any other scene that we can witness, yet they all resonate strongly with the human visual system. We are able appreciate such images because evolution endowed us with high dynamic range wide-angle stereoscopic sensors, namely the eyes. But even equipped with those high performance sensors, our complex nervous system choose to hallucinate most of what we see based on prior experience. These are only fragments of why automating the human visual system through computer vision tasks is so difficult. For humans, the meaning of a pixel values is not only defined by its surroundings and context, but also by what happened in the past, as shaped by the decades of learning experienced by the observer.

As we begin to understand better our visual system, it becomes clear that, just like humans, complex vision tasks must rely on priors to be performed successfully. Those priors must be extracted from collected experience, using data as its own representation. This is the main topic of this dissertation: developing data-driven approaches to solve problems that are ill-posed when considering them exclusively from a physics or geometric perspective. Specifically, two problems will be covered: the problem of 3D surface reconstruction using photometric cues, and lighting and camera calibration. In both cases, we are interested in cases when the environment is mostly uncontrolled, resulting in an under-constrained problem.

%``There is no model; there is only color.'' (Paul Cézanne)

% First chapter
Photometric stereo (PS) is a popular, dense shape reconstruction technique that has matured extensively over nearly 40 years~\cite{woodham-opteng-80} to work with complex materials and lighting conditions~\cite{alldrin-cvpr-08,basri-ijcv-07,johnson-cvpr-11,oxholm-eccv-12}.
%Given the excellent PS results obtained in carefully designed laboratory setups,
Simply put, this technique proposes to recover the 3D surface normals of an object observed under varying illumination.
PS is reputed to give exceptional accuracy on surface normal estimation in fully calibrated environments, where the light is controlled.
%It was also successfully coupled with multiview stereo techniques to provide great 3D reconstruction outdoors~\cite{snavely-ijcv-08}.
Recent investigations have turned to the more challenging problem of outdoor PS under uncontrolled, natural illumination. However, it turns out the sun follows a coplanar path throughout a single day, leaving the PS problem under-constrained. To solve this issue, recent approaches proposed to capture images over the course of many months~\cite{ackermann-cvpr-12,abrams-eccv-12}. This time interval provides enough shifting to the sun plane to constrain correctly the PS problem.

In this thesis, instead of trying to be invariant to natural illumination, we propose to leverage its richness to solve the Outdoor Photometric Stereo problem. We will discover, as Jean Paul Richter puts it, ``a sky full of silent suns''. This brings us to our first main contribution:
\begin{quotation}
\textbf{Single-Day Photometric Stereo} We present a systematic analysis of the expected performance of PS algorithms in outdoor settings on a single day or less, and then propose data-driven approaches to solve the single-day PS problem under various weather conditions.
\end{quotation}

\todo{wrap up}

The advent of social medias has brought a phenomenal influx of images of all sorts each day to public databases, giving rise to data-driven approaches and enabling the development of data-hungry machine learning algorithms such as deep neural networks. These methods bring a new paradigm to tackle vision problems: learning priors on natural images. These priors (initial beliefs on a probability distribution) are effectively additional constraints over classical physics- or geometric-based approaches which can enhance solutions of ill-posed problems. Such data-driven approaches are only possible given the recent increase in computing speed and storage capacity of contemporary computers, allowing the handling of the staggering amount of data available nowadays.

In this dissertation, we argue that machine learning can be used to learn priors on generic scenes and natural illumination. Using this additional information, it is possible to improve current calibration techniques, leading to our second contribution:
\begin{quotation}
\textbf{Single Image Lighting and Camera Calibration} We present two single-image learning-based approaches to perform outdoor lighting and camera calibration. The proposed methods works on generic scenes and does not requires a specific object to be present in the image.
\end{quotation}

\todo{ending}

\section*{Overview}

This thesis is grouped into two main axes: 1) surface reconstruction through photometric cues, and 2) learning-based lighting and camera calibration estimation. Both research axes are explored through a data-driven paradigm, each one leveraging between thousands and millions of images, representing highly dimensional data.

First, chapter~\ref{ch1} provides an in-depth analysis of the information contained in photometric cues throughout a single day and gives performance bounds on Photometric Stereo when performed on intervals down to a single hour. Upon investigation, we found that partially cloudy days brought enough constraints to solve the PS problem using an adapted PS algorithm. However, we show that sunny days in general are lacking the constraints to provide a stable surface reconstruction. In chapter~\ref{ch2}, we go one step further than what is possible using exclusively photometric cues. Since there are not enough information in a single sunny day to do a stable surface reconstruction solely from photometric cues, we employ a deep learning model to learn priors on local surface geometry and sun trajectory patterns. This additional information brings enough supplemental constrains to the PS problem to allow stable surface reconstructions.

Chapters~\ref{ch3} and~\ref{ch4} propose to extract priors from large datasets and utilize them to improve single-image outdoor lighting and camera calibration, respectively. Most current outdoor lighting estimation techniques rely exclusively on handcrafted features, limiting their application to a determined environment, for example urban scenes~\cite{lalonde-ijcv-12}. By learning features on scenes devoid of specific content, we propose a lighting estimation approach that is robust to generic scenes. Finally, the last chapter covers the problem of camera calibration from a single image. An emphasis is put on extrinsics calibration with respect to the earth, with a focus on finding the horizon within the image, even when hidden within the image. We further analyze human tolerance to errors on those calibration parameters.


\todo{remove bib section number}

\bibliographystyle{abbrvnat}
\bibliography{library}
